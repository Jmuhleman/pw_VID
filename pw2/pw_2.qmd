---
title: "Travail pratique VID"
subtitle: "TP #2" 
author:
  - name: Julien Muhlemann
    email: julien.muhlemann@heig-vd.ch
    affiliations:
      - name: Département TIC
highlight-style: github
format:
  html:
    theme: cosmo
    monobackgroundcolor: rgb(255,230,240)
    backgroundcolor: rgb(250,250,250)
    toc: true
    toc-location: left
    #reference-location: margin
    reference-location: document
    code-line-numbers: true
  pdf:
    pdf-engine: pdflatex
    toc: true
    number-sections: false
    colorlinks: true
    
date: 'last-modified'
date-format: 'D MMMM, YYYY'
number-sections: false
editor: 
  visual
---






description des données, 
calligraphie latek
précisions dans explications
PAS d'ENGLISH
PLUS de commentaires



# Introduction

blablabla




# Exercice 1

## a  Calculer le coefficient de corrélation entre la taille et l'age.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}
kalama <- read.table("kalama.txt", header = TRUE, sep = "", dec = ".")

print(kalama)
```

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}


print(coeff_correlation <- cor(kalama$taille, kalama$age, method = "pearson"))

```

## b  Tracer le nuage de points taille versus age.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

plot(kalama)

```

## c Estimer les coefficients $\beta_{0}$ et $\beta_{1}$ par la méthode des moindres carrés. Enregistrer le résultat de l'ajustement du modèle dans l'objet kalama.lm de R.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}


kalama.lm <- lm(age ~ taille, data=kalama)
#par(mfrow=c(2,2), pty="s")
#plot(kalama.lm, which=1:4)
```

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}
kalama.lm
```

Donc nous avons:

$\beta_{0}$ = -100.842 et $\beta_{1}$ = 1.557

## d Ajuster sur le graphique la droite des moindres carrés en utilisant la fonction abline().

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}


coeff <- coefficients(kalama.lm)

eq <- paste0("y = ", round(coeff[2], 1), " * x ", 
            ifelse(coeff[1] >= 0, " + ", " - "), 
            abs(round(coeff[1], 1)))

plot(kalama$taille, kalama$age, main = eq, 
     xlab = "Taille", ylab = "age") 

abline(kalama.lm, col = "blue", lwd = 2)
```

## e Estimer la variance des erreurs $\sigma^2$.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

kalama.lm <- lm(age ~ taille, data=kalama)
par(mfrow=c(1,1), pty="s")
plot(kalama.lm, which=1)

```

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

model_summary <- summary(kalama.lm)
mse <- model_summary$sigma^2
#model_summary
print(mse)
```

## f Déterminer la valeur du coefficient de détermination R2 de la régression.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

model_summary <- summary(kalama.lm)
r_squared <- model_summary$r.squared
print(r_squared)

```
## g Effectuer un diagnostic du modèle ajusté à l’aide des graphiques appropriés.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}
library(ggResidpanel)
resid_panel(kalama.lm, plots="all")
resid_interact(kalama.lm)

```

## h En combinant les résultats obtenus en d), f) et g), qualifier l’ajustement du modèle aux
données observées.

Nous pouvons dire que le modèle est bien ajusté aux données observées. En effet, le coefficient de détermination est de 0.988, ce qui signifie que 98% de la variance de la variable dépendante est expliquée par la variable indépendante. De plus, les graphiques de diagnostic montrent que les résidus sont relativement bien distribués autour de 0 (variance constante) et ne présentent pas de structure particulière (indépendance des erreurs). Nous pouvons également dire que la somme des résidus est proche de 0 (espérance proche de 0).

Nous pouvons observer dans le Quantile-Quantile plot (QQ plot) que les résidus suivent une distribution proche de la loi normale. Ce que confirme l'histogramme des résidus et la boite à moustache sur la même ligne.

La distance de Cook nous permet de visualiser les observations qui ont le plus d'impact sur le modèle. Nous pouvons voir que les observations 1 et 2 ont un impact plus important que les autres observations. Ceci est certainement dû au fait que ces deux observations sont des valeurs aberrantes. En prenant un seuil de $\ 4/n$ nous avons donc 0.3 comme ligne pointillée.

Nous pouvons observer le graphique de la régression en haut à droite. Celui-ci nous indique que le modèle de manière générale est bien adapté à faire des prédictions sur de nouvelles données. Cependant, il est important de noter que nous disposons de relativement peu d'observations donc il est possible que le modèle ne soit pas aussi robuste avec de nouvelles données.





## i Tester à un niveau de signification de 5% si la pente de la droite de régression est significativement
différente de zéro.


```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

summary_result <- summary(kalama.lm)
attributes(summary_result$coefficients)

p_value <- summary_result$coefficients[2, 4] 
print(p_value)

```


Nous avons une p-valeur de ~4.43E-11 qui est inférieure à 0.05. Nous pouvons donc rejeter l'hypothèse nulle selon laquelle la pente de la droite de régression est égale à zéro. Nous pouvons donc conclure que la pente de la droite de régression est significativement différente de zéro.




# Exercice 2


## a Introduire les données observées dans votre session actuelle de R en complétant les commandes
ci-dessous.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

mortalite.pnb <- data.frame(pays=c("Allemagne RFA","Autriche","Belgique","Danemark","Espagne",
"France","Grèce","Irlande","Italie","Luxembourg","Pays-Bas",
"Portugal","Royaume-Uni","Suisse"),

PNB=c(190, 128, 180, 212, 56, 192, 68, 98, 110, 197, 155, 40, 181, 233),
mortalite=c(24, 28, 24, 19, 37, 22, 34, 25, 36, 24, 14, 65, 20, 18))

```



## b Déterminer le résumé des variables en utilisant la fonction summary().

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}


summary(mortalite.pnb)

```



## c Reproduire le graphique de nuage de points de la page suivante représentant la mortalité
infantile (y) en fonction du produit national brut (x). Pour y parvenir, il convient d’utiliser
les librairies tidyverse et ggrepel.

```{r, warning=FALSE, results=TRUE, fig.height=8, fig.width=8}

library(tidyverse)
library(ggrepel)

ggplot(mortalite.pnb, aes(x=PNB, y=mortalite, label=pays)) +
  geom_point() +
  geom_text_repel() +
  xlab("Produit National Brut") +
  ylab("Mortalité infantile") +
  ggtitle("PNB et mortalité infantile") +
  theme_minimal() +
  geom_smooth(method = "lm", se = FALSE, color = "blue")

```


Nous pouvons observer que le Portugal est un pays qui ne suit pas la tendance générale dessinée par les points. En effet, le Portugal a un PNB relativement faible par rapport à la mortalité infantile. Cela peut être dû à plusieurs facteurs, tels que la qualité des soins de santé, l'accès aux soins de santé, la qualité de l'eau, etc. Les Pays-bas se démarquent également, mais dans le sens inverse. les Pays-Bas ont un PNB relativement élevé par rapport à la mortalité infantile.


## d Déterminer l’équation de la droite de régression linéaire ajustée sur le nuage de points à
l’aide de la méthode des moindres carrés.


```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

mortalite.pnb.lm <- lm(mortalite ~ PNB, data=mortalite.pnb)
summary(mortalite.pnb.lm)

```
Nous pouvons voir que les paramètres estimés sont les suivants:
$\ \hat{y} = 51.01 * PNB - 0.16$



## e Donner le coefficient de corrélation linéaire r.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

correlation <- cor(mortalite.pnb$PNB, mortalite.pnb$mortalite)
print(correlation)

```

## f En déduire le coefficient de détermination R^2.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}


r_squared <- summary(mortalite.pnb.lm)$r.squared
print(r_squared)

```

## g Effectuer une vérification des hypothèses inhérentes au modèle à l’aide des graphiques
appropriés.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

par(mfrow=c(2,2), pty="s")
plot(mortalite.pnb.lm, which=1:4)

```


```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

summary(mortalite.pnb.lm)$coefficients


```
Nous pouvons effectuer la vérification d'hypothèse en utilisant les valeurs p des coefficients. Ces valeurs sont toutes inférieures à 0.05, ce qui signifie que nous pouvons rejeter l'hypothèse nulle selon laquelle les coefficients sont égaux à zéro. Nous pouvons donc conclure que le modèle est significatif.

Nous avons donc:
$\ \hat{y}  = 51.01 * x - 0.16$

Le graphe des résidus en haut à gauche nous indique que nous avons une espérance qui se rapproche de 0 puisque la somme des résidus tends vers 0. La variance des résidus est constante, ce qui est une bonne chose. Le graphe des résidus en fonction des valeurs prédites nous montre que les résidus sont répartis de manière aléatoire autour de 0 car nous n'avons pas de signal cyclique (I.E. sinus...).

Le graphe Q-Q  nous indique que les résidus suivent une loi normale. Néanmoins nous avons un point qui s'écarte de la droite, ceci est certainement le Portugal (12).

Le graphe de la distance de Cook nous indique que nous avons à nouveau le Portugal qui à une grande influence sur la régression.




## h Donner à l’aide du modèle ajusté une prédiction de la mortalité infantile pour un PNB de
100. Pour y parvenir, il convient d’utiliser la fonction predict().

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}
xnew <- matrix(c(100), nrow=1)
colnames(xnew) <- c("PNB")
xnew <- as.data.frame(xnew)
predict(mortalite.pnb.lm, xnew, interval="pred")

```

## i Un modèle de régression linéaire a été ajusté en considérant la mortalité comme variable
de réponse et le logarithme naturel du PNB comme variable explicative. Le coefficient de
détermination associé à l’ajustement de ce modèle vaut 0.74.

Nous pouvons en premier lieu afficher les résultats statistiques du modèle. Nous pouvons voir que nous obtenons un coefficient de détermination de 0.74, ce qui est un bon résultat. Cela signifie que 74% de la variance de la mortalité infantile est expliquée par le PNB. Nous avons un meilleur modèle que précédemment (0.74 > 0.71).


```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

mortalite.pnb$logPNB <- log(mortalite.pnb$PNB)
mortalite.pnb.lm2 <- lm(mortalite ~ logPNB, data=mortalite.pnb)
summary(mortalite.pnb.lm2)

```

Nous pouvons également afficher les graphes correpondant à l'analyse des résidus et des hypothèses du modèle. Nous pouvons voir que les résidus suivent une loi normale selon le 'Q-Q Residuals', la variance est constante et la somme des résidus tend vers 0 (espérance de 0) selon le 'Residuals vs Fitted. Le 'Scale-Location' nous montre que la variance des résidus est constante. Enfin, le 'Cook's distance' nous montre que le Portugal a toujours une grande influence sur la régression.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}
par(mfrow=c(2,2), pty="s")
plot(mortalite.pnb.lm2, which=1:4)

```


# Exercice 3

La taille de la portée (lsize), le poids du corps (bodywt) et le poids du cerveau (brainwt) ont
été relevés dans un échantillon formé de 20 souris. On se propose d’étudier la relation qui peut
exister entre le poids du cerveau (variable de réponse) et la taille de la portée et le poids du corps
(variables explicatives).
Les données se trouvent dans le fichier litters.rds qu’il faut lire dans votre session actuelle de
R à l’aide de la fonction readRDS().


## a Tracer le graphique des corrélations et des nuages de points se trouvant ci-dessous à l’aide
de la fonction ggpairs() de la librairie GGally.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

library(GGally)
litters <- readRDS("litters.rds")
ggpairs(litters)

```


## b Existe-t-il une relation entre les deux variables explicatives lsize et bodywt?
Nous pouvons voir qu'il existe une relation linéaire inversement proportionnelle entre lsize et bodywt. En effet, plus la taille de la portée est grande, plus le poids du corps est faible.



## c Qu’en est-il de la relation entre la variable de réponse brainwt et les deux variables explicatives
à considérer l’une après l’autre ?

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

litters.lm <- lm(brainwt ~ lsize, data=litters)
r2 <- summary(litters.lm)$r.squared
print(c)

```

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

litters.lm <- lm(brainwt ~ bodywt, data=litters)
r2 <- summary(litters.lm)$r.squared
print(r2)


```
Nous avons calculé le coefficient de détermination entre la taille du cerveau et le poids ainsi que la longueur. Nous observons que le coefficient de détermination est plus élevé pour le poids du corps que pour la taille de la portée. Cela signifie que le poids du corps explique mieux la taille du cerveau que la taille de la portée. A noter que la relation est négative.


## d Répondre aux mêmes questions en utilisant la librairie rgl de R et en complétant le code
ci-dessous.


```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}  
library(rgl)
plotids <- with(litters, plot3d(litters$brainwt, litters$bodywt, litters$lsize, type="s", col="blue"))
rglwidget(elementId = "plot3drgl")
```



## e Sera-t-il commode de distinguer clairement les effects des deux variables explicatives sur
la variable de réponse ?

Il est difficile de distinguer les effets des deux variables explicatives sur la variable de réponse. En effet, les points sont superposés et il est difficile de comprendre la relation entre les variables dans un espace 3D.



## f Déterminer l’équation du modèle de régression linéaire multiple obtenue par la méthode
des moindres carrés.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

litters.lm <- lm(brainwt ~ lsize, data=litters)
summary(litters.lm)

```
```{r, warning=TRUE, results=TRUE, fig.height=10, fig.width=10}

litters.lm <- lm(brainwt ~ bodywt, data=litters)
summary(litters.lm)
```

Nous pouvons utiliser la méthode summary pour obtenir l'équation du modèle. Nous obtenons:
pour la variable bodywt:
$\ \hat{y} = 0.010 * bodywt + 0.335$
pour la variable lsize:
$\ \hat{y} = -0.004 * lsize + 0.447$




## g Dresser la table qui résume l’ajustement du modèle à l’aide de la fonction summary().
Tester séparément la significativité de chaque variable explicative par rapport au modèle
complet.


Quelles variables explicatives sont significatives à un niveau de signification de 5%? Que
peut-on conclure en considérant également les graphiques des corrélations et des nuages
de points tracés ci-dessus ?



Voir les 2 tables dressées en f.

Nous pouvons voir que les deux variables explicatives (lsize et bodywt) sont significatives à un niveau de signification de 5%.
L'estimateur du poids du corps est significatif à 0.000158 et l'estimateur de la taille de la portée s'élève à 0.00344. Les deux p-valeurs sont donc inférieures à 0.05. La probabilité de l'hypothèse nulle est donc inférieure à 5% et nous pouvons donc la rejeter.

En outre, les deux variables expliquent la taille du cerveau. Cependant, nous pouvons voir que le poids du corps explique mieux la taille du cerveau que la taille de la portée. En effet, le coefficient de détermination est plus élevé pour le poids du corps que pour la taille de la portée.




## h Tracer le graphique du nuage de points ci-dessous en complétant les commandes


```{r, warning=TRUE, results=TRUE, fig.height=10, fig.width=10}
library(scatterplot3d)

s3d <- scatterplot3d(litters$lsize, litters$bodywt, litters$brainwt, main = "",
color="midnightblue", xlab="litter size", ylab="body weight",
zlab="brain weight", angle = -60, pch=21, bg="orange")
litters.fit <- lm(brainwt ~ lsize + bodywt, data = litters)

s3d$plane3d(litters.fit, draw_polygon=TRUE, lty.box="solid")

```



## i Déterminer le coefficient de détermination R2 et le coefficient de détermination ajusté R2adj
associés au modèle. Que peut-on conclure ?

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}
model_summary <- summary(litters.fit)
print(model_summary)

```
Nous avons donc un coefficient de détermination de 0.65 et un coefficient de détermination ajusté de 0.61. Cela signifie que 65% de la variance de la taille du cerveau est expliquée par le poids du corps et la taille de la portée. Cela signifie que le modèle explique bien la taille du cerveau.

Nous pouvons conclure que le modèle est significatif et capture bien la taille du cerveau. Cependant il reste 35% de la variance qui n'est pas expliquée par le modèle. Cela pourrait venir de facteurs non inclus dans les données. Le coefficient ajusté de 0.61 tient compte du nombre de variable dans le modèle. La légère baisse par rapport au $\\R^2$


## j Effectuer une vérification des hypothèses inhérentes au modèle à l’aide des graphiques
appropriés. À votre avis, que peut-on faire pour améliorer la qualité du modèle ajusté ?


```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}
par(mfrow=c(2,2))
plot(litters.fit)

```



Nous pouvons voir que les résidus sont distribués de manière aléatoire autour de 0. Cela signifie que les résidus sont normalement distribués. Nous pouvons également voir que les résidus sont distribués de manière homogène. Cela signifie que la variance des résidus est constante. Enfin, nous pouvons voir que les résidus ne sont pas corrélés. Cela signifie que les résidus ne sont pas corrélés entre eux.

Pour améliorer la qualité du modèle ajusté, nous pourrions ajouter des variables explicatives supplémentaires. Cela pourrait nous aider à expliquer davantage la variance de la taille du cerveau. Nous pourrions également essayer de transformer les variables explicatives pour voir si cela améliore le modèle. En utilisant un logarithme par exemple.



# Exercice 4

## a Tracer le graphique des corrélations et des nuages de points se trouvant ci-dessous à l’aide
de la fonction ggpairs() de la librairie GGally.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}
library(GGally)
library(readxl)

wine <- read_excel("Wine.xlsx")
ggpairs(wine, title = "Correlation des vins")

```

Quelles sont les variables explicatives qui semblent au mieux expliquer la variable de réponse
?

Les variables explicatives qui semblent le mieux expliquer la variable de réponse sont les variables aroma et flavour. En effet, ces variables ont une corrélation élevée avec la variable de réponse 0.707 et 0.790. Cela signifie que ces variables sont fortement corrélées avec la variable de réponse et pourraient être de bons prédicteurs de la variable réponse quality.


## b Déterminer l’équation du modèle de régression linéaire multiple obtenue par la méthode
des moindres carrés.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}
wine.lm <- lm(wine$Quality ~ wine$Aroma + wine$Flavor, data=wine)
summary(wine.lm)
```

Nous pouvons utiliser la méthode summary pour obtenir l'équation du modèle. Nous obtenons:
$\ \hat{y} = 0.52 * aroma + 1.17 * flavor + 4.35$

## c Dresser la table qui résume l’ajustement du modèle. Tester séparément la significativité de
chaque variable explicative par rapport au modèle complet.


Nous allons tester la significativité de chaque variable explicative par rapport au modèle complet.

Ordonnée à l'origine: 0.000127 -> est inférieure à 0.05 donc significative
wine$Aroma: 0.069 -> est supérieure à 0.05 donc non significative
wine$Flavor: 0.00029 -> est inférieure à 0.05 donc significative


## c Quelles variables explicatives sont significatives à un niveau de signfication de 5%? Que
peut-on conclure en considérant également les graphiques des corrélations et des nuages
de points tracés en a) ?


Nous pouvons voir que la variable explicative flavor est significative à un niveau de signification de 5%. En revanche, la variable explicative aroma n'est pas significative à un niveau de signification de 5%. Cela signifie que la variable explicative flavor est un bon prédicteur de la variable réponse quality, tandis que la variable explicative aroma n'est pas un bon prédicteur de la variable réponse quality.

Néanmoins, nous pouvons voir que la variable explicative aroma est fortement corrélée avec la variable réponse quality. Cela est certainement dû à une multicollinéarité entre les variables explicatives aroma et flavor. La corrélation entre Flavor et aroma est de 0.737 et comme Flavor est corrélée à Quality alors Aroma le sera avec Quality également. Heureusement en analysant les p-valeurs nous nous aperçevons que Aroma n'est pas significative.




## d Déterminer le coefficient de détermination $\\R^2$ et le coefficient de détermination ajusté $\\R^2adj$
associés au modèle.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}
model_summary <- summary(wine.lm)
print(model_summary)

```

Nous avons donc un coefficient de détermination de 0.65 et un coefficient de détermination ajusté de 0.61. Cela signifie que 65% de la variance de la qualité du vin est capturée par les variables aroma et flavor. Cela signifie que le modèle explique moyennement la qualité du vin.



## e Faire une recherche bibliographique pour expliquer en utilisant vos propres mots ce que
représentent ces critères, leur qualité et leur défaut.

$\\\mathfrak{Résumé}$  $\\\mathfrak{des}$  $\\\mathfrak{Modèles}$

Coefficient de détermination ajusté $\\R^2adj$ :
$\\R^2_{\text{adj}} = 1 - \frac{(1 - R^2) \cdot (n - 1)}{n - p - 1}$
p = nombre de variables explicatives
n = nombre d'observations
un $\\R^2_{\text{adj}}$ élevé indique un modèle expliquant bien la variable réponse.

Cet indicateur pénalise les modèles qui ont un grand nombre de variable explicatives non significatives. Il est donc plus fiable que le coefficient de détermination $\\R^2$ pour comparer des modèles avec un nombre différent de variables explicatives. Cependant, il est plus difficile à interpréter que le coefficient de détermination $\\R^2$.



Critère d'Akaike (AIC) : 
$\\\text{AIC} = 2k - 2\ln(L)$
k = nombre de paramètres du modèle
L = vraisemblance maximale du modèle
un AIC petit indique un bon modèle

Le critère d'Akaike mesure la qualité d'un modèle tout en pénalisant sa complexité. Ce critère penalise les avec trop de paramètres pour éviter le surajustement (overfitting). Cela en fait un moyen adapté pour comparer des modèles dont les paramètres sont variables. A noter que cet indicateur suppose une distribution normale des erreurs.



Critère d'information Bayésien (BIC) :
$\\\text{BIC} = k \cdot \ln(n) - 2 \ln(L)$
k = nombre de paramètres du modèle
n = nombre d'observations
L = vraisemblance maximale du modèle
un BIC petit indique un bon modèle

De manière analogue à l'AIC, le BIC pénalise les modèles avec trop de paramètres. Cependant, le BIC pénalise plus fortement les modèles avec un grand nombre de paramètres. Cela en fait un indicateur plus adapté pour comparer des modèles avec un grand nombre de paramètres. Attention toutefois cet indicateur pourrait se révéler trop stricte et exclure des modèles intéressants.


Critère de Mallows (Cp) :
$\\C_p = \frac{\sum (y_i - \hat{y}_i)^2}{s^2} - n + 2p $
$\\s^2$ = estimation de la variance des résidus du modèle complet
p = nombre de variables explicatives
n = nombre d'observations
un $\\C_p$ proche de p indique un bon modèle

Ce critère compare un modèle de régression avec un modèle qui inclurait toutes les variables possibles. Il prend en compte le biais et la variance pour évaluer la qualité du modèle. Cela en fait un outil intéressant pour détecter les modèles qui sont bien équilibrés en biais et variance. A noter que ce critère encourage également des modèles plus simples.



## f Utiliser la librairie leaps et appliquer les critères R2a
dj, BIC et Cp en adaptant le code cidessous.


```{r, warning=FALSE, results=TRUE, fig.height=8, fig.width=8}
library(leaps)
choix <- regsubsets(Quality~., data=wine, nbest=1, nvmax=11)
plot(choix, scale="adjr2", col="midnightblue")
leaps <- regsubsets(Quality~., data=wine, nbest=10)
summary(leaps)

```









