---
title: "Travail pratique VID"
subtitle: "TP #2" 
author:
  - name: Julien Muhlemann
    email: julien.muhlemann@heig-vd.ch
    affiliations:
      - name: Département TIC
highlight-style: github
format:
  html:
    theme: cosmo
    monobackgroundcolor: rgb(255,230,240)
    backgroundcolor: rgb(250,250,250)
    toc: true
    toc-location: left
    #reference-location: margin
    reference-location: document
    code-line-numbers: true
  pdf:
    pdf-engine: pdflatex
    toc: true
    number-sections: false
    colorlinks: true
    
date: 'last-modified'
date-format: 'D MMMM, YYYY'
number-sections: false
editor: 
  visual
---






description des données, 
calligraphie latek
précisions dans explications
PAS d'ENGLISH
PLUS de commentaires



# Introduction

blablabla




# Exercice 1

## a  Calculer le coefficient de corrélation entre la taille et l'age.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}
kalama <- read.table("kalama.txt", header = TRUE, sep = "", dec = ".")

print(kalama)
```

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}


print(coeff_correlation <- cor(kalama$taille, kalama$age, method = "pearson"))

```

## b  Tracer le nuage de points taille versus age.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

plot(kalama)

```

## c Estimer les coefficients $\beta_{0}$ et $\beta_{1}$ par la méthode des moindres carrés. Enregistrer le résultat de l'ajustement du modèle dans l'objet kalama.lm de R.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}


kalama.lm <- lm(age ~ taille, data=kalama)
#par(mfrow=c(2,2), pty="s")
#plot(kalama.lm, which=1:4)
```

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}
kalama.lm
```

Donc nous avons:

$\beta_{0}$ = -100.842 et $\beta_{1}$ = 1.557

## d Ajuster sur le graphique la droite des moindres carrés en utilisant la fonction abline().

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}


coeff <- coefficients(kalama.lm)

eq <- paste0("y = ", round(coeff[2], 1), " * x ", 
            ifelse(coeff[1] >= 0, " + ", " - "), 
            abs(round(coeff[1], 1)))

plot(kalama$taille, kalama$age, main = eq, 
     xlab = "Taille", ylab = "age") 

abline(kalama.lm, col = "blue", lwd = 2)
```

## e Estimer la variance des erreurs $\sigma^2$.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

kalama.lm <- lm(age ~ taille, data=kalama)
par(mfrow=c(1,1), pty="s")
plot(kalama.lm, which=1)

```

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

model_summary <- summary(kalama.lm)
mse <- model_summary$sigma^2
#model_summary
print(mse)
```

## f Déterminer la valeur du coefficient de détermination R2 de la régression.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

model_summary <- summary(kalama.lm)
r_squared <- model_summary$r.squared
print(r_squared)

```
## g Effectuer un diagnostic du modèle ajusté à l’aide des graphiques appropriés.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}
library(ggResidpanel)
resid_panel(kalama.lm, plots="all")
resid_interact(kalama.lm)

```

## h En combinant les résultats obtenus en d), f) et g), qualifier l’ajustement du modèle aux
données observées.

Nous pouvons dire que le modèle est bien ajusté aux données observées. En effet, le coefficient de détermination est de 0.988, ce qui signifie que 98% de la variance de la variable dépendante est expliquée par la variable indépendante. De plus, les graphiques de diagnostic montrent que les résidus sont relativement bien distribués autour de 0 (variance constante) et ne présentent pas de structure particulière (indépendance des erreurs). Nous pouvons également dire que la somme des résidus est proche de 0 (espérance proche de 0).

Nous pouvons observer dans le Quantile-Quantile plot (QQ plot) que les résidus suivent une distribution proche de la loi normale. Ce que confirme l'histogramme des résidus et la boite à moustache sur la même ligne.

La distance de Cook nous permet de visualiser les observations qui ont le plus d'impact sur le modèle. Nous pouvons voir que les observations 1 et 2 ont un impact plus important que les autres observations. Ceci est certainement dû au fait que ces deux observations sont des valeurs aberrantes. En prenant un seuil de $\ 4/n$ nous avons donc 0.3 comme ligne pointillée.

Nous pouvons observer le graphique de la régression en haut à droite. Celui-ci nous indique que le modèle de manière générale est bien adapté à faire des prédictions sur de nouvelles données. Cependant, il est important de noter que nous disposons de relativement peu d'observations donc il est possible que le modèle ne soit pas aussi robuste avec de nouvelles données.





## i Tester à un niveau de signification de 5% si la pente de la droite de régression est significativement
différente de zéro.


```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

summary_result <- summary(kalama.lm)
attributes(summary_result$coefficients)

p_value <- summary_result$coefficients[2, 4] 
print(p_value)

```


Nous avons une p-valeur de ~4.43E-11 qui est inférieure à 0.05. Nous pouvons donc rejeter l'hypothèse nulle selon laquelle la pente de la droite de régression est égale à zéro. Nous pouvons donc conclure que la pente de la droite de régression est significativement différente de zéro.




# Exercice 2


## a Introduire les données observées dans votre session actuelle de R en complétant les commandes
ci-dessous.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

mortalite.pnb <- data.frame(pays=c("Allemagne RFA","Autriche","Belgique","Danemark","Espagne",
"France","Grèce","Irlande","Italie","Luxembourg","Pays-Bas",
"Portugal","Royaume-Uni","Suisse"),

PNB=c(190, 128, 180, 212, 56, 192, 68, 98, 110, 197, 155, 40, 181, 233),
mortalite=c(24, 28, 24, 19, 37, 22, 34, 25, 36, 24, 14, 65, 20, 18))

```



## b Déterminer le résumé des variables en utilisant la fonction summary().

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}


summary(mortalite.pnb)

```



## c Reproduire le graphique de nuage de points de la page suivante représentant la mortalité
infantile (y) en fonction du produit national brut (x). Pour y parvenir, il convient d’utiliser
les librairies tidyverse et ggrepel.

```{r, warning=FALSE, results=TRUE, fig.height=8, fig.width=8}

library(tidyverse)
library(ggrepel)

ggplot(mortalite.pnb, aes(x=PNB, y=mortalite, label=pays)) +
  geom_point() +
  geom_text_repel() +
  xlab("Produit National Brut") +
  ylab("Mortalité infantile") +
  ggtitle("PNB et mortalité infantile") +
  theme_minimal() +
  geom_smooth(method = "lm", se = FALSE, color = "blue")

```


Nous pouvons observer que le Portugal est un pays qui ne suit pas la tendance générale dessinée par les points. En effet, le Portugal a un PNB relativement faible par rapport à la mortalité infantile. Cela peut être dû à plusieurs facteurs, tels que la qualité des soins de santé, l'accès aux soins de santé, la qualité de l'eau, etc. Les Pays-bas se démarquent également, mais dans le sens inverse. les Pays-Bas ont un PNB relativement élevé par rapport à la mortalité infantile.


## d Déterminer l’équation de la droite de régression linéaire ajustée sur le nuage de points à
l’aide de la méthode des moindres carrés.


```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

mortalite.pnb.lm <- lm(mortalite ~ PNB, data=mortalite.pnb)
summary(mortalite.pnb.lm)

```
Nous pouvons voir que les paramètres estimés sont les suivants:
$\ \hat{y} = 51.01 * PNB - 0.16$



## e Donner le coefficient de corrélation linéaire r.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

correlation <- cor(mortalite.pnb$PNB, mortalite.pnb$mortalite)
print(correlation)

```

## f En déduire le coefficient de détermination R^2.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}


r_squared <- summary(mortalite.pnb.lm)$r.squared
print(r_squared)

```

## g Effectuer une vérification des hypothèses inhérentes au modèle à l’aide des graphiques
appropriés.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

par(mfrow=c(2,2), pty="s")
plot(mortalite.pnb.lm, which=1:4)

```


```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

summary(mortalite.pnb.lm)$coefficients


```
Nous pouvons effectuer la vérification d'hypothèse en utilisant les valeurs p des coefficients. Ces valeurs sont toutes inférieures à 0.05, ce qui signifie que nous pouvons rejeter l'hypothèse nulle selon laquelle les coefficients sont égaux à zéro. Nous pouvons donc conclure que le modèle est significatif.

Nous avons donc:
$\ \hat{y}  = 51.01 * x - 0.16$

Le graphe des résidus en haut à gauche nous indique que nous avons une espérance qui se rapproche de 0 puisque la somme des résidus tends vers 0. La variance des résidus est constante, ce qui est une bonne chose. Le graphe des résidus en fonction des valeurs prédites nous montre que les résidus sont répartis de manière aléatoire autour de 0 car nous n'avons pas de signal cyclique (I.E. sinus...).

Le graphe Q-Q  nous indique que les résidus suivent une loi normale. Néanmoins nous avons un point qui s'écarte de la droite, ceci est certainement le Portugal (12).

Le graphe de la distance de Cook nous indique que nous avons à nouveau le Portugal qui à une grande influence sur la régression.




## h Donner à l’aide du modèle ajusté une prédiction de la mortalité infantile pour un PNB de
100. Pour y parvenir, il convient d’utiliser la fonction predict().

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}
xnew <- matrix(c(100), nrow=1)
colnames(xnew) <- c("PNB")
xnew <- as.data.frame(xnew)
predict(mortalite.pnb.lm, xnew, interval="pred")

```

## i Un modèle de régression linéaire a été ajusté en considérant la mortalité comme variable
de réponse et le logarithme naturel du PNB comme variable explicative. Le coefficient de
détermination associé à l’ajustement de ce modèle vaut 0.74.

Nous pouvons en premier lieu afficher les résultats statistiques du modèle. Nous pouvons voir que nous obtenons un coefficient de détermination de 0.74, ce qui est un bon résultat. Cela signifie que 74% de la variance de la mortalité infantile est expliquée par le PNB. Nous avons un meilleur modèle que précédemment (0.74 > 0.71).


```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

mortalite.pnb$logPNB <- log(mortalite.pnb$PNB)
mortalite.pnb.lm2 <- lm(mortalite ~ logPNB, data=mortalite.pnb)
summary(mortalite.pnb.lm2)

```

Nous pouvons également afficher les graphes correpondant à l'analyse des résidus et des hypothèses du modèle. Nous pouvons voir que les résidus suivent une loi normale selon le 'Q-Q Residuals', la variance est constante et la somme des résidus tend vers 0 (espérance de 0) selon le 'Residuals vs Fitted. Le 'Scale-Location' nous montre que la variance des résidus est constante. Enfin, le 'Cook's distance' nous montre que le Portugal a toujours une grande influence sur la régression.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}
par(mfrow=c(2,2), pty="s")
plot(mortalite.pnb.lm2, which=1:4)

```


# Exercice 3

La taille de la portée (lsize), le poids du corps (bodywt) et le poids du cerveau (brainwt) ont
été relevés dans un échantillon formé de 20 souris. On se propose d’étudier la relation qui peut
exister entre le poids du cerveau (variable de réponse) et la taille de la portée et le poids du corps
(variables explicatives).
Les données se trouvent dans le fichier litters.rds qu’il faut lire dans votre session actuelle de
R à l’aide de la fonction readRDS().


## a Tracer le graphique des corrélations et des nuages de points se trouvant ci-dessous à l’aide
de la fonction ggpairs() de la librairie GGally.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

library(GGally)
litters <- readRDS("litters.rds")
ggpairs(litters)

```


## b Existe-t-il une relation entre les deux variables explicatives lsize et bodywt?
Nous pouvons voir qu'il existe une relation linéaire inversement proportionnelle entre lsize et bodywt. En effet, plus la taille de la portée est grande, plus le poids du corps est faible.



## c Qu’en est-il de la relation entre la variable de réponse brainwt et les deux variables explicatives
à considérer l’une après l’autre ?

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

litters.lm <- lm(brainwt ~ lsize, data=litters)
r2 <- summary(litters.lm)$r.squared
print(c)

```

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

litters.lm <- lm(brainwt ~ bodywt, data=litters)
r2 <- summary(litters.lm)$r.squared
print(r2)


```
Nous avons calculé le coefficient de détermination entre la taille du cerveau et le poids ainsi que la longueur. Nous observons que le coefficient de détermination est plus élevé pour le poids du corps que pour la taille de la portée. Cela signifie que le poids du corps explique mieux la taille du cerveau que la taille de la portée. A noter que la relation est négative.


## d Répondre aux mêmes questions en utilisant la librairie rgl de R et en complétant le code
ci-dessous.


```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}  
library(rgl)
plotids <- with(litters, plot3d(litters$brainwt, litters$bodywt, litters$lsize, type="s", col="blue"))
rglwidget(elementId = "plot3drgl")
```



## e Sera-t-il commode de distinguer clairement les effects des deux variables explicatives sur
la variable de réponse ?

Il est difficile de distinguer les effets des deux variables explicatives sur la variable de réponse. En effet, les points sont superposés et il est difficile de comprendre la relation entre les variables dans un espace 3D.



## f Déterminer l’équation du modèle de régression linéaire multiple obtenue par la méthode
des moindres carrés.

```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

litters.lm <- lm(brainwt ~ lsize + bodywt, data=litters)
summary(litters.lm)

```

Nous pouvons utiliser la méthode summary pour obtenir l'équation du modèle. Nous obtenons:
$\ \hat{y} = 0.010 * bodywt - 0.335$



## g Dresser la table qui résume l’ajustement du modèle à l’aide de la fonction summary().
Tester séparément la significativité de chaque variable explicative par rapport au modèle
complet.
Quelles variables explicatives sont significatives à un niveau de signification de 5%? Que
peut-on conclure en considérant également les graphiques des corrélations et des nuages
de points tracés ci-dessus ?



```{r, warning=FALSE, results=TRUE, fig.height=10, fig.width=10}

summary(litters.lm)



```






































































